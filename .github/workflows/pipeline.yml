name: Data Pipeline Workflow

on:
  workflow_dispatch: # Trigger manually from GitHub UI
  schedule:
    - cron: "0 3 * * *" # Optional: Run daily at 3 AM UTC

jobs:
  data_pipeline:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the repository
    - name: Checkout code
      uses: actions/checkout@v3

    # Step 2: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.9'

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Set up Google Cloud credentials
      run: echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" > service-account-key.json

    # Step 4: Fetch data from API and save to Excel
    - name: Fetch data and save to Excel
      run: python scripts/fetch_data.py

    # Step 5: Authenticate with Google Cloud
    - name: Authenticate with Google Cloud
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

    # Step 6: Upload file to Google Cloud Storage
    - name: Upload to Google Cloud Storage
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
      run: python scripts/upload_to_gcs.py
